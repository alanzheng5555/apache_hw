# PE (Processing Element) 内核技术规格文档

## 1. 概述

PE内核是Apache_HW推理优化架构的核心计算单元，专为Transformer模型的高效推理而设计。本规格文档详细描述PE内核的功能特性、内部结构和性能参数。

## 2. 设计目标

### 2.1 性能目标
- **最大化浮点性能**: 针对AI推理优化的浮点运算单元
- **高能效比**: 在保证性能的前提下降低功耗
- **Transformer优化**: 专门针对Transformer计算模式优化
- **大模型支持**: 支持数十亿乃至数百亿参数的模型推理

### 2.2 功能目标
- **半精度计算**: 重点优化FP16/BF16运算
- **矩阵运算加速**: 高效的矩阵乘法和相关运算
- **低延迟**: 最小化关键路径延迟
- **可扩展性**: 支持多个PE协同工作

## 3. 内部架构

### 3.1 计算单元

#### 3.1.1 向量处理单元 (VPU)
- **宽度**: 512位或1024位向量寄存器
- **支持的数据类型**: 
  - FP16 (IEEE 754 half precision)
  - BF16 (Brain Floating Point)
  - FP32 (IEEE 754 single precision)
  - INT8, INT16, INT32 整数运算
- **运算能力**:
  - 向量加法、减法、乘法
  - 向量融合乘加 (FMA)
  - 向量比较、选择操作

#### 3.1.2 专用MAC阵列
- **规模**: 16x16 或 32x32 MAC单元阵列
- **数据类型**: 专门优化FP16/BF16矩阵乘法
- **吞吐量**: 每时钟周期完成256或1024次FP16 MAC操作
- **累加器**: 支持高精度累加避免溢出

#### 3.1.3 激活函数单元
- **内置激活函数**:
  - GELU (Gaussian Error Linear Unit)
  - ReLU (Rectified Linear Unit)
  - Swish/SiLU
  - Sigmoid
  - Tanh
- **实现方式**: 查找表(LUT) + 插值算法

### 3.2 存储层次

#### 3.2.1 寄存器文件
- **标量寄存器**: 32个32位通用寄存器
- **向量寄存器**: 32个512/1024位向量寄存器
- **矩阵寄存器**: 16个矩阵寄存器，用于暂存矩阵运算结果

#### 3.2.2 本地缓存
- **指令缓存**: 32KB，4路组相联
- **数据缓存**: 64KB，4路组相联
- **特征**: 支持突发传输，低延迟访问

### 3.3 控制单元

#### 3.3.1 指令解码器
- **指令格式**: RISC-V扩展指令集
- **扩展指令**:
  - `vfma.vv`: 向量融合乘加
  - `vmmul.ss`: 矩阵乘法 (small × small)
  - `vmmul.sl`: 矩阵乘法 (small × large)
  - `vgelu.v`: GELU激活函数
  - `vsoftmax.v`: Softmax计算

#### 3.3.2 调度器
- **发射宽度**: 每周期发射4条指令
- **重排序缓冲区**: 64项
- **保留站**: 整数64项，浮点64项

## 4. Transformer专项优化

### 4.1 注意力机制加速

#### 4.1.1 Query-Key矩阵乘法
- **优化**: 针对Q×K^T矩阵乘法优化
- **缓存**: 专用的Q/K缓存减少重复加载
- **流水线**: 三阶段流水线(Q预处理-乘法-结果后处理)

#### 4.1.2 Softmax加速
- **算法**: 数值稳定的Softmax实现
- **精度**: 支持FP16/BF16的高精度Softmax
- **吞吐量**: 每时钟处理64个元素

#### 4.1.3 Value加权求和
- **优化**: 针对Attention输出的矩阵乘法
- **缓存**: 重用Attention权重

### 4.2 MLP层加速

#### 4.2.1 矩阵乘法优化
- **输入矩阵**: 支持变长序列长度
- **权重矩阵**: 针对MLP结构优化的内存布局
- **输出累加**: 支持Bias加法的融合

#### 4.2.2 激活函数融合
- **FMA+激活**: 乘加运算后直接激活
- **批归一化融合**: BN参数融合到矩阵乘法中

### 4.3 归一化加速

#### 4.3.1 Layer Normalization
- **算法**: 基于减均值-平方-求和-开方的高效实现
- **精度**: 支持FP32中间计算保证数值稳定性
- **吞吐量**: 每时钟处理32个元素

#### 4.3.2 RMS Normalization
- **优化**: 专门针对Llama等模型的RMSNorm优化
- **算法**: 简化的归一化计算流程

## 5. 内存接口

### 5.1 本地内存接口
- **带宽**: 512GB/s @ 1GHz
- **协议**: AXI4接口
- **预取**: 智能预取机制

### 5.2 互联接口
- **PE间通信**: 2D Mesh或Torus拓扑
- **带宽**: 每个方向32GB/s
- **协议**: 片上网络 (NoC)

## 6. 性能参数

### 6.1 计算性能
- **FP16峰值性能**: 128 TFLOPS (假设1024个PE @ 1GHz)
- **BF16峰值性能**: 128 TFLOPS
- **FP32峰值性能**: 64 TFLOPS
- **INT8峰值性能**: 256 TOPS

### 6.2 功耗参数
- **峰值功耗**: 25W per PE (估算)
- **典型功耗**: 15W per PE (估算)
- **能效比**: 5-8 TOPS/W (INT8), 2-4 TFLOPS/W (FP16)

### 6.3 面积参数
- **估算面积**: 2-4 mm² per PE (7nm工艺)
- **存储占比**: ~40% 面积用于本地存储
- **计算占比**: ~35% 面积用于计算单元

## 7. 指令集架构

### 7.1 基础指令扩展
```
# 矩阵运算指令
vmmul.vv vd, vj, vk     # 向量-向量矩阵乘法
vmmul.vx vd, vj, rs1    # 向量-标量矩阵乘法
vfma.vvv vd, vj, vk     # 向量融合乘加
vfma.vvs vd, vj, rs1    # 向量-标量融合乘加

# 激活函数指令
vgelu.v vd, vj          # GELU激活函数
vsoftmax.v vd, vj       # Softmax函数
vlayernorm.v vd, vj     # Layer Normalization

# Transformer专用指令
vattn.qkv vd, vq, vk, vv # QKV注意力计算
vattn.softmax vd, vj     # Attention Softmax
```

### 7.2 内存访问指令
- **向量化加载/存储**: 支持strided访问模式
- **矩阵加载/存储**: 优化的矩阵数据传输
- **缓存控制**: 显式的缓存管理指令

## 8. 验证策略

### 8.1 功能验证
- **单元测试**: 验证各个功能单元
- **集成测试**: 验证整体功能正确性
- **回归测试**: 确保功能不变性

### 8.2 性能验证
- **仿真模型**: RTL级性能仿真
- **基准测试**: 在真实模型上的性能测试
- **对比分析**: 与现有方案的性能对比

## 9. 实现考虑

### 9.1 时序约束
- **时钟频率**: 目标1-2GHz
- **关键路径**: 重点关注MAC阵列和存储访问
- **流水线深度**: 5-8级流水线

### 9.2 面积优化
- **资源共享**: 在非同时使用的单元间共享资源
- **时分复用**: 通过时分复用减少硬件资源
- **可配置性**: 根据应用需求配置硬件资源

## 10. 未来扩展

### 10.1 架构增强
- **稀疏计算**: 支持稀疏矩阵运算
- **量化支持**: 更多量化格式支持
- **新激活函数**: 支持新型激活函数

### 10.2 生态支持
- **编译器优化**: 针对架构的编译器优化
- **运行时调度**: 智能任务调度算法
- **框架集成**: 与主流AI框架集成

---
*本文档定义了PE内核的核心规格，将指导后续的详细设计和实现工作。*