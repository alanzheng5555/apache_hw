# 64-Core Chip Performance Analysis

## 1. 芯片规格

| 参数 | 值 |
|------|-----|
| Core 数量 | 64 (8×8 Mesh) |
| 时钟频率 | 1 GHz (默认) |
| MAC/周期/Core | 1 |
| 峰值吞吐量 | **64 GFLOPS** |

---

## 2. 4096×4096 矩阵乘法性能

### 计算量

```
总 MAC 操作数 = 4096³ = 68,719,476,736 (687 亿次)
```

### 理论执行时间

| 条件 | 时间 |
|------|------|
| **理论最短时间** | **1.07 秒** |
| 实际估计 (含通信) | ~1.3 秒 |
| 保守估计 | 1.5-2.0 秒 |

### 频率对比

| 频率 | 峰值性能 | 执行时间 |
|------|----------|----------|
| 500 MHz | 32 GFLOPS | 2.15 秒 |
| **1 GHz** | **64 GFLOPS** | **1.07 秒** |
| 2 GHz | 128 GFLOPS | 0.54 秒 |

---

## 3. RTL 仿真时间估计

### 仿真规模对比

| 矩阵大小 | Core 数 | MAC 操作 | 仿真周期估计 | 仿真时间* |
|----------|---------|----------|-------------|----------|
| 8×8 | 1 | 512 | ~10,000 | **几秒** ✓ |
| 64×64 | 64 | 262,144 | ~1,000,000 | 1-2 分钟 ✓ |
| 256×256 | 64 | 16,777,216 | ~20,000,000 | 20-30 分钟 |
| 1024×1024 | 64 | 1,073,741,824 | ~500,000,000 | 8-12 小时 |
| **4096×4096** | 64 | 68,719,476,736 | ~30,000,000,000 | **2-4 天** |

*基于 100 MHz 仿真速度估计

### 建议

**先运行小规模测试验证功能正确性：**

```bash
# 快速功能验证 (8×8)
./run_tb.sh 8

# 性能预估测试 (64×64)  
./run_tb.sh 64
```

---

## 4. 并行化策略

### 分块矩阵乘法

```
4096 = 8 × 512

每个 Core 负责: 512 × 512 子矩阵块
```

### Core 数据需求

| 数据 | 大小 | 说明 |
|------|------|------|
| A 子块 | 1 MB | 本地输入 |
| B 子块 | 8 MB | 从其他 Core 接收 |
| C 子块 | 1 MB | 输出结果 |
| **总计** | **10 MB/Core** | |

**芯片总内存需求**: 64 × 10 MB = **640 MB**

---

## 5. 仿真测试指南

### 运行测试

```bash
cd /home/alan/.openclaw/workspace/apache_hw/design/chip_top/tb

# 快速测试 (8×8)
./run_tb.sh 8

# 中等测试 (64×64)
./run_tb.sh 64

# 指定仿真器
SIMULATOR=questasim ./run_tb.sh 64
```

### 测试流程

```
1. 生成测试矩阵
   - A[i][j] = i + j
   - B[i][j] = i × j + 1
   - C = A × B

2. 分配数据到各 Core
   - 按 512×512 块分发
   
3. 启动所有 Core
   - pe_start = 64'hFFFF_FFFF_FFFF_FFFF

4. 等待完成
   - pe_done == 64'hFFFF_FFFF_FFFF_FFFF

5. 收集结果
   - 读回各 Core 计算结果

6. 验证正确性
   - 与参考实现对比
   - 允许误差: ±0.01
```

---

## 6. 性能瓶颈分析

| 瓶颈 | 时间占比 | 优化建议 |
|------|----------|----------|
| MAC 计算 | ~85% | 增加 MAC 单元 |
| Core 间通信 | ~10% | 脉动阵列 |
| 内存 I/O | ~5% | 双缓冲 |

### 预期优化效果

| 优化 | 加速比 | 预计时间 |
|------|--------|----------|
| 基准 | 1× | 1.3 秒 |
| 双缓冲 | 1.2× | 1.1 秒 |
| 脉动阵列 | 1.4× | 0.9 秒 |
| 2 GHz 频率 | 2× | 0.65 秒 |

---

## 7. 结论

### 4096×4096 矩阵乘法

| 指标 | 值 |
|------|-----|
| **理论最短时间** | **1.07 秒** |
| **实际估计** | **1.3 秒** |
| 仿真周期 | ~300 亿周期 |
| RTL 仿真时间 | 2-4 天 |

### 与其他系统对比

| 系统 | 峰值 GFLOPS | 执行时间 |
|------|-------------|----------|
| **我们的 64-core (1 GHz)** | 64 | **~1.3 秒** |
| NVIDIA V100 GPU | 125,000 | ~0.001 秒 |
| Intel Xeon (64-core) | 2,000 | ~0.07 秒 |

**结论**: 这是合理的自定义 AI 加速器基线性能。
